{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFH2oVacPR9HSj1XYRMerQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoBanerjee/GAN/blob/main/FirstAttempt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t3Lee6DBPYP1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def load_images(image_folder):\n",
        "    image_data = []\n",
        "    for img_name in os.listdir(image_folder):\n",
        "        if img_name.endswith('.png'):\n",
        "            img_path = os.path.join(image_folder, img_name)\n",
        "            img = load_img(img_path, target_size=(128, 128))\n",
        "            img = img_to_array(img)\n",
        "            img = (img - 127.5) / 127.5\n",
        "            image_data.append(img)\n",
        "    return np.array(image_data)\n",
        "\n",
        "image_folder = '/content/'\n",
        "images = load_images(image_folder)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, Model\n",
        "def build_generator(latent_dim):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(256 * 8 * 8, activation=\"relu\", input_dim=latent_dim))\n",
        "    model.add(layers.Reshape((8, 8, 256)))\n",
        "    model.add(layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.ReLU())\n",
        "    model.add(layers.Conv2DTranspose(3, kernel_size=4, strides=2, padding=\"same\", activation='tanh'))  # 3 for RGB\n",
        "    return model\n",
        "\n",
        "def build_discriminator(image_shape):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\", input_shape=image_shape))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Conv2D(256, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "GG2GEzCVRsJh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 100\n",
        "image_shape = (128, 128, 3)  # Update based on your data\n",
        "\n",
        "generator = build_generator(latent_dim)\n",
        "discriminator = build_discriminator(image_shape)"
      ],
      "metadata": {
        "id": "lsRhSGVnRzwq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([batch_size, latent_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "        disc_loss = cross_entropy(tf.ones_like(real_output), real_output) + \\\n",
        "                    cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
      ],
      "metadata": {
        "id": "2H1rP0ZIR7cr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(len(images)).batch(batch_size)\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for image_batch in train_dataset:\n",
        "        train_step(image_batch)\n",
        "    print(f\"Epoch {epoch + 1} completed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao7TyuVASBP3",
        "outputId": "bdb704d0-7955-4e83-a05f-b7fe4c729978"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5818: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 completed\n",
            "Epoch 2 completed\n",
            "Epoch 3 completed\n",
            "Epoch 4 completed\n",
            "Epoch 5 completed\n",
            "Epoch 6 completed\n",
            "Epoch 7 completed\n",
            "Epoch 8 completed\n",
            "Epoch 9 completed\n",
            "Epoch 10 completed\n",
            "Epoch 11 completed\n",
            "Epoch 12 completed\n",
            "Epoch 13 completed\n",
            "Epoch 14 completed\n",
            "Epoch 15 completed\n",
            "Epoch 16 completed\n",
            "Epoch 17 completed\n",
            "Epoch 18 completed\n",
            "Epoch 19 completed\n",
            "Epoch 20 completed\n",
            "Epoch 21 completed\n",
            "Epoch 22 completed\n",
            "Epoch 23 completed\n",
            "Epoch 24 completed\n",
            "Epoch 25 completed\n",
            "Epoch 26 completed\n",
            "Epoch 27 completed\n",
            "Epoch 28 completed\n",
            "Epoch 29 completed\n",
            "Epoch 30 completed\n",
            "Epoch 31 completed\n",
            "Epoch 32 completed\n",
            "Epoch 33 completed\n",
            "Epoch 34 completed\n",
            "Epoch 35 completed\n",
            "Epoch 36 completed\n",
            "Epoch 37 completed\n",
            "Epoch 38 completed\n",
            "Epoch 39 completed\n",
            "Epoch 40 completed\n",
            "Epoch 41 completed\n",
            "Epoch 42 completed\n",
            "Epoch 43 completed\n",
            "Epoch 44 completed\n",
            "Epoch 45 completed\n",
            "Epoch 46 completed\n",
            "Epoch 47 completed\n",
            "Epoch 48 completed\n",
            "Epoch 49 completed\n",
            "Epoch 50 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_and_save_images(model, epoch, num_examples, save_dir='/content/generated_images'):\n",
        "    # Ensure the save directory exists\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    # Generate images\n",
        "    noise = tf.random.normal([num_examples, latent_dim])\n",
        "    predictions = model(noise, training=False)\n",
        "\n",
        "    # Plot the generated images\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow((predictions[i, :, :, :] + 1) / 2)\n",
        "        plt.axis('off')\n",
        "\n",
        "    # Save the image\n",
        "    plt.savefig(f'{save_dir}/image_at_epoch_{epoch:04d}.png')\n",
        "    plt.close()\n",
        "\n",
        "# Example usage\n",
        "num_examples_to_generate = 16\n",
        "generate_and_save_images(generator, 0, num_examples_to_generate)  # Use 0 for epoch if generating after training\n"
      ],
      "metadata": {
        "id": "KSeJRhtjSGMu"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}